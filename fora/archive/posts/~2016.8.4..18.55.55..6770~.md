---
type: post
date: ~2016.8.4..18.55.55..6770
title: (profiler) Secret voodoo folk knowledge
author: ~fyr
navsort: bump
navuptwo: true
comments: reverse
---

Pulled from mailing list archives:

```
---------- Forwarded message ----------
From: Curtis Yarvin <curtis@tlon.io>
Date: Wed, Dec 3, 2014 at 9:48 AM
Subject: [urbit] profiling
To: "urbit-dev@googlegroups.com" <urbit-dev@googlegroups.com>
```

If you pull the latest vere there's a working profiler. To use it, run vere with
`-P`.  You'll get a profiling report after the process exits.  A good way to use
it is with the new `-D` (dry run) option.  Create a sub, sync it with the
server, start :chat or something, then quit.  Then rerun with `-D -P`.  It will
ignore your checkpoint and replay all the events, profiling. 

That way, you have a stable test case.  Bear in mind, if you take a pier and
change urb/urbit.pill, then replay the old events with the new kernel, you've
done something we call a "brain transplant" - this is, well, not exactly normal,
but in many cases can be quite useful. The profiler produces a call graph dump
of all the jet-labeled cores that ran (whether or not there is actually a jet or
not).  If you want a node to be in the profile, jet it.  CPU usage is divided
into:

```
    events: 13n 40c 4g 41m 0f
```

These are percentages - "n" is the nock interpreter, "c" is C jets, "g" is
jet binding glue, "m" is the allocator, "f" is nock fragment (/) chasing. In
general, preliminary results reveal that (besides some blocking in the old event
system) there are two reasons Urbit is slow.  One is that we don't cache the
dynamic compilation operations we perform on every event.  Two is that there's
no optimized path in the memory allocator specifically for allocating cells,
which are obviously almost all allocations. 

If anyone out there is feeling ambitious, getting the "m" path faster with a
special case for cell allocation probably wouldn't be very hard...

```
---------- Forwarded message ----------
From: Curtis Yarvin <curtis.yarvin@gmail.com>
Date: Thu, Jan 8, 2015 at 5:04 PM
Subject: news items
```

Fortunately, the profiler works pretty well and makes it quite easy to trace
performance cost.  You can run the profiler yourself with `-P`; the recommended
approach is to create a fake zod (with `-F -I ~zod`), do some stuff, then quit,
and rerun `-P -D`.  `-D` means "dry run" and re-executes the whole event log, then
exits.

After exiting a `-P` session, you'll get a profile trace that looks like:

```
    events: 22n 46c 5g 26m 0f 
    label: /swim/wink/vent/arvo/hoon/mood/k164
    price: 97
    shape: 21n 46c 5g 26m 0f 
    into:
      /wink/vent/arvo/hoon/mood/k164: 15
      /slym/hoon/mood/k164: 3.758
      /hoon/mood/k164: 5
      /mint/ut/hoon/mood/k164: 82
      /peek/ut/hoon/mood/k164: 25
      /ut/hoon/mood/k164: 4
      /sump/wink/vent/arvo/hoon/mood/k164: 491
      /souk/wink/vent/arvo/hoon/mood/k164: 411
      /sike/wink/vent/arvo/hoon/mood/k164: 168
    label: /slym/hoon/mood/k164
    price: 73
    shape: 14n 55c 4g 25m 0f 
    into:
      /div/hoon/mood/k164: 1
      /nest/ut/hoon/mood/k164: 6
      /fun/stew/hoon/mood/k164: 82
      /sub/hoon/mood/k164: 4
      /rsh/hoon/mood/k164: 67
      /play/ut/hoon/mood/k164: 85
      /add/hoon/mood/k164: 66
      /by/hoon/mood/k164: 1
      /hoon/mood/k164: 117
      /shim/hoon/mood/k164: 3
      /call/ford-d/mood/k164: 2.577
      /po/hoon/mood/k164: 1
      /get/by/hoon/mood/k164: 2
      /mint/ut/hoon/mood/k164: 6
      /mul/hoon/mood/k164: 91
      /cook/hoon/mood/k164: 4
      /peek/ut/hoon/mood/k164: 95
      /ut/hoon/mood/k164: 77
      /raw/og/hoon/mood/k164: 10
      /look/hoon/mood/k164: 2
      /cut/hoon/mood/k164: 1
      /vest/hoon/mood/k164: 3
      /mod/hoon/mood/k164: 217
      /dec/hoon/mood/k164: 7
      /end/hoon/mood/k164: 7
      /cold/hoon/mood/k164: 1
      /roll/hoon/mood/k164: 16
      /turn/hoon/mood/k164: 75
    from:
      /swim/wink/vent/arvo/hoon/mood/k164: 3.758
```

And so on.  The "21n 46c 5g 26m 0f" means we spent about 21% of our time in the
nock interpreter, 46% of the time in C jets, 5% of the time in glue between nock
and C, 26% of the time in the memory allocator (because we don't have a fastpath
for allocating cells), and 0% of the time evaluating the nock / operator (which
surprises me a little).

We then use the jet dashboard to identify call graph nodes that are
performance-relevant.  For instance, we spend 97% of our time in ++swim, the
main event handler (for obvious reasons), and 75% of our time in ++slym (which
it calls to run an event).  The numbers after each line are the number of
samples which have the routine in their call stack.
