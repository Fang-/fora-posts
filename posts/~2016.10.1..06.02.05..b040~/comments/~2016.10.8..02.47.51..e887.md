## `~hodmut-datdex-narmes-sivrym--somhec-patnyd-dozdys-binzod`
This tells you, obviously, that you're spending a lot of time in Nock.  (And maybe that you're running in Hoon code that should use tail calls but doesn't).

Basically every time we notice that Urbit is unusably slow, we go in and optimize it and make it fast enough to use.  As you point out, this leaves many people with slower machines feeling the slow.  Which is not good marketing, if nothing else.

C-level profiling a la Instruments, or whatever, is not amazingly helpful when you're spending most of your time in Nock.  Basically, when optimizing Urbit, your goal is to not spend most of your time in Nock.  That said, I know we could spend *way* less time in the allocator.

Fortunately there is also an Urbit profiling flag, -P.  It works with the stock vere binary.  The Urbit profiler uses the same annotations as jets to specify the execution structure of the system -- the first step in optimizing at the user level is to add jet annotations, the second is to implement jets where needed (or actually make the algorithms more efficient, of course).

A normal profiler will get the whole symbol table and map it to all basic blocks, whereas ours only shows you the symbols you care about in a performance sense.  This actually makes Urbit profiling results considerably easier to follow than much more sophisticated C tools.  Splitting the call graph at relevant annotations, for each annotated arm -P will tell you how long your code spent in Nock, C, Nock-C glue, and the memory allocator.  This usually turns up something actionable...